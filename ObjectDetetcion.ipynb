{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtD0UcpMZRe7J10dfZAHph",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyeshaSajid2/object_detection_app/blob/main/ObjectDetetcion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-v7qCS8A0ql",
        "outputId": "6d974054-19d4-48bb-efb8-74d1808bdc5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpjwsatwfb'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name='conv2d_input')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138586026593440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138586026734720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138585982588832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138585982597984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138585981934528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138585981936816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138585981942096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138585981942976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138585982126736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138585982130256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Reload the model after saving any modifications\n",
        "model = tf.keras.models.load_model(\"/trained-model.h5\")\n",
        "\n",
        "# Convert to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(\"weed_detection_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Input\n",
        "\n",
        "# Define your model using Input layer\n",
        "model = Sequential([\n",
        "    Input(shape=(512, 512, 3)),  # Specify input shape using Input layer\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    # Add more layers as needed\n",
        "    Flatten(),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "6MD3sUlYFDf0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"weed_detection_model.h5\")  # Save your model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUzSPt5jFIJ4",
        "outputId": "47f7a665-db27-4f31-af46-4a6d50b995af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the model\n",
        "model = tf.keras.models.load_model(\"weed_detection_model.h5\")\n",
        "\n",
        "# Convert the model to TFLite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(\"weed_detection_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iZvfTzGFQsu",
        "outputId": "81403e14-1204-4ecd-dc95-7b261240d74b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpvel42iv2'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138585979001088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138585979004784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138585979080896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138585979085296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load TFLite model and allocate tensors\n",
        "interpreter = tf.lite.Interpreter(model_path=\"weed_detection_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Prepare input data\n",
        "input_shape = input_details[0]['shape']  # (1, 512, 512, 3)\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "\n",
        "# Set input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "# Run the model\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the output\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M191YpHGFtcA",
        "outputId": "93b05de5-93a3-4abf-9382-b6c3a5213f15"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5688392  0.43116075]]\n"
          ]
        }
      ]
    }
  ]
}